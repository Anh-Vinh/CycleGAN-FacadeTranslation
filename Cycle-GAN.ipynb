{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anhvinh/cycle-gan?scriptVersionId=222178057\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import tensorflow as tf\n\nimport os\nimport time\nimport torch\nimport pathlib\n\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom matplotlib import pyplot as plt\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:55:45.681Z","iopub.execute_input":"2025-02-12T12:55:45.681348Z","iopub.status.idle":"2025-02-12T12:55:45.688749Z","shell.execute_reply.started":"2025-02-12T12:55:45.681317Z","shell.execute_reply":"2025-02-12T12:55:45.688115Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_HEIGHT = 256\nIMG_WIDTH = 256\nBUFFER_SIZE = 400\nBATCH_SIZE = 4\nNUM_EPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:55:48.225696Z","iopub.execute_input":"2025-02-12T12:55:48.226313Z","iopub.status.idle":"2025-02-12T12:55:48.230181Z","shell.execute_reply.started":"2025-02-12T12:55:48.226279Z","shell.execute_reply":"2025-02-12T12:55:48.229289Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"dataset_name = \"facades\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:55:52.116083Z","iopub.execute_input":"2025-02-12T12:55:52.116899Z","iopub.status.idle":"2025-02-12T12:55:52.120571Z","shell.execute_reply.started":"2025-02-12T12:55:52.116862Z","shell.execute_reply":"2025-02-12T12:55:52.119759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"_URL = f'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/{dataset_name}.tar.gz'\n\npath_to_zip = tf.keras.utils.get_file(\n    fname=f\"{dataset_name}.tar.gz\",\n    origin=_URL,\n    extract=True)\n\npath_to_zip  = pathlib.Path(path_to_zip)\n\nPATH = path_to_zip.parent/dataset_name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:55:54.745339Z","iopub.execute_input":"2025-02-12T12:55:54.745673Z","iopub.status.idle":"2025-02-12T12:56:02.289951Z","shell.execute_reply.started":"2025-02-12T12:55:54.745644Z","shell.execute_reply":"2025-02-12T12:56:02.28925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(PATH.parent.iterdir())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:57:50.681942Z","iopub.execute_input":"2025-02-12T12:57:50.68232Z","iopub.status.idle":"2025-02-12T12:57:50.689096Z","shell.execute_reply.started":"2025-02-12T12:57:50.682289Z","shell.execute_reply":"2025-02-12T12:57:50.688327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_image = tf.io.read_file(str(PATH / 'train/1.jpg'))\nsample_image = tf.io.decode_jpeg(sample_image)\nprint(sample_image.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:57:53.379347Z","iopub.execute_input":"2025-02-12T12:57:53.379939Z","iopub.status.idle":"2025-02-12T12:57:53.398059Z","shell.execute_reply.started":"2025-02-12T12:57:53.379902Z","shell.execute_reply":"2025-02-12T12:57:53.397206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nplt.imshow(sample_image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:57:55.736547Z","iopub.execute_input":"2025-02-12T12:57:55.73688Z","iopub.status.idle":"2025-02-12T12:57:56.074097Z","shell.execute_reply.started":"2025-02-12T12:57:55.73685Z","shell.execute_reply":"2025-02-12T12:57:56.073193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load(image_file):\n  # Read and decode an image file to a uint8 tensor\n  image = tf.io.read_file(image_file)\n  image = tf.io.decode_jpeg(image)\n\n  # Split each image tensor into two tensors:\n  # - one with a real building facade image\n  # - one with an architecture label image \n  w = tf.shape(image)[1]\n  w = w // 2\n  input_image = image[:, w:, :]\n  real_image = image[:, :w, :]\n\n  # Convert both images to float32 tensors\n  input_image = tf.cast(input_image, tf.float32)\n  real_image = tf.cast(real_image, tf.float32)\n\n  return input_image, real_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:05.886187Z","iopub.execute_input":"2025-02-12T12:58:05.886534Z","iopub.status.idle":"2025-02-12T12:58:05.893496Z","shell.execute_reply.started":"2025-02-12T12:58:05.886499Z","shell.execute_reply":"2025-02-12T12:58:05.892474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inp, re = load(str(PATH / 'train/100.jpg'))\n# Casting to int for matplotlib to display the images\nplt.figure()\nplt.imshow(inp / 255.0)\nplt.figure()\nplt.imshow(re / 255.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:08.148513Z","iopub.execute_input":"2025-02-12T12:58:08.149217Z","iopub.status.idle":"2025-02-12T12:58:08.807747Z","shell.execute_reply.started":"2025-02-12T12:58:08.149181Z","shell.execute_reply":"2025-02-12T12:58:08.806745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The facade training set consist of 400 images\nBUFFER_SIZE = 400\n# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\nBATCH_SIZE = 1\n# Each image is 256x256 in size\nIMG_WIDTH = 256\nIMG_HEIGHT = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:14.792405Z","iopub.execute_input":"2025-02-12T12:58:14.793144Z","iopub.status.idle":"2025-02-12T12:58:14.797486Z","shell.execute_reply.started":"2025-02-12T12:58:14.793108Z","shell.execute_reply":"2025-02-12T12:58:14.796611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def resize(input_image, real_image, height, width):\n  input_image = tf.image.resize(input_image, [height, width],\n                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n  real_image = tf.image.resize(real_image, [height, width],\n                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n  return input_image, real_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:17.259164Z","iopub.execute_input":"2025-02-12T12:58:17.259875Z","iopub.status.idle":"2025-02-12T12:58:17.264568Z","shell.execute_reply.started":"2025-02-12T12:58:17.25984Z","shell.execute_reply":"2025-02-12T12:58:17.2636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_crop(input_image, real_image):\n  stacked_image = tf.stack([input_image, real_image], axis=0)\n  cropped_image = tf.image.random_crop(\n      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n\n  return cropped_image[0], cropped_image[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:19.445862Z","iopub.execute_input":"2025-02-12T12:58:19.446229Z","iopub.status.idle":"2025-02-12T12:58:19.451026Z","shell.execute_reply.started":"2025-02-12T12:58:19.446197Z","shell.execute_reply":"2025-02-12T12:58:19.450102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalizing the images to [-1, 1]\ndef normalize(input_image, real_image):\n  input_image = (input_image / 127.5) - 1\n  real_image = (real_image / 127.5) - 1\n\n  return input_image, real_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:21.564668Z","iopub.execute_input":"2025-02-12T12:58:21.565049Z","iopub.status.idle":"2025-02-12T12:58:21.569616Z","shell.execute_reply.started":"2025-02-12T12:58:21.565009Z","shell.execute_reply":"2025-02-12T12:58:21.568655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tf.function()\ndef random_jitter(input_image, real_image):\n  # Resizing to 286x286\n  input_image, real_image = resize(input_image, real_image, 286, 286)\n\n  # Random cropping back to 256x256\n  input_image, real_image = random_crop(input_image, real_image)\n\n  if tf.random.uniform(()) > 0.5:\n    # Random mirroring\n    input_image = tf.image.flip_left_right(input_image)\n    real_image = tf.image.flip_left_right(real_image)\n\n  return input_image, real_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:23.672214Z","iopub.execute_input":"2025-02-12T12:58:23.672875Z","iopub.status.idle":"2025-02-12T12:58:23.678279Z","shell.execute_reply.started":"2025-02-12T12:58:23.672838Z","shell.execute_reply":"2025-02-12T12:58:23.677256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 6))\nfor i in range(4):\n  rj_inp, rj_re = random_jitter(inp, re)\n  plt.subplot(2, 2, i + 1)\n  plt.imshow(rj_inp / 255.0)\n  plt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:27.784362Z","iopub.execute_input":"2025-02-12T12:58:27.785371Z","iopub.status.idle":"2025-02-12T12:58:28.24482Z","shell.execute_reply.started":"2025-02-12T12:58:27.785332Z","shell.execute_reply":"2025-02-12T12:58:28.244032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image_train(image_file):\n  input_image, real_image = load(image_file)\n  input_image, real_image = random_jitter(input_image, real_image)\n  input_image, real_image = normalize(input_image, real_image)\n\n  return input_image, real_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:32.421135Z","iopub.execute_input":"2025-02-12T12:58:32.421807Z","iopub.status.idle":"2025-02-12T12:58:32.426201Z","shell.execute_reply.started":"2025-02-12T12:58:32.421769Z","shell.execute_reply":"2025-02-12T12:58:32.42528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image_test(image_file):\n  input_image, real_image = load(image_file)\n  input_image, real_image = resize(input_image, real_image,\n                                   IMG_HEIGHT, IMG_WIDTH)\n  input_image, real_image = normalize(input_image, real_image)\n\n  return input_image, real_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:34.540271Z","iopub.execute_input":"2025-02-12T12:58:34.5413Z","iopub.status.idle":"2025-02-12T12:58:34.546722Z","shell.execute_reply.started":"2025-02-12T12:58:34.541244Z","shell.execute_reply":"2025-02-12T12:58:34.54574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.list_files(str(PATH / 'train/*.jpg'))\ntrain_dataset = train_dataset.map(load_image_train,\n                                  num_parallel_calls=tf.data.AUTOTUNE)\ntrain_dataset = train_dataset.shuffle(32)\ntrain_dataset = train_dataset.batch(BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:36.558284Z","iopub.execute_input":"2025-02-12T12:58:36.558627Z","iopub.status.idle":"2025-02-12T12:58:37.516597Z","shell.execute_reply.started":"2025-02-12T12:58:36.558595Z","shell.execute_reply":"2025-02-12T12:58:37.515698Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n  test_dataset = tf.data.Dataset.list_files(str(PATH / 'test/*.jpg'))\nexcept tf.errors.InvalidArgumentError:\n  test_dataset = tf.data.Dataset.list_files(str(PATH / 'val/*.jpg'))\ntest_dataset = test_dataset.map(load_image_test)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:39.182825Z","iopub.execute_input":"2025-02-12T12:58:39.183652Z","iopub.status.idle":"2025-02-12T12:58:39.260022Z","shell.execute_reply.started":"2025-02-12T12:58:39.183615Z","shell.execute_reply":"2025-02-12T12:58:39.259174Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## Generator","metadata":{}},{"cell_type":"code","source":"# Thay thế Instance Normalization tự định nghĩa bằng BatchNormalization vì TF không hỗ trợ (PyTorch có)\ndef convolutional_block(x, filters, kernel_size=3, strides=2, padding='same'):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    \n    x = layers.Conv2D(filters, kernel_size, strides, padding, kernel_initializer=initializer, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    return x\n\ndef residual_block(x, filters, kernel_size=3, strides=1, padding='same'):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    \n    shortcut = x\n    x = layers.Conv2D(filters, kernel_size, strides, padding, kernel_initializer=initializer, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    x = layers.Conv2D(filters, kernel_size, strides, padding, kernel_initializer=initializer, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Add()([shortcut, x])\n    x = layers.ReLU()(x)\n    return x\n\n# Fractionally-strided convolution\ndef upsample_block(x, filters, kernel_size=3, strides=2, padding='same'):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    # x = layers.UpSampling2D(size=2)(x)\n    # x = layers.Conv2D(filters, kernel_size, strides, padding)(x)\n    x = layers.Conv2DTranspose(filters, kernel_size, strides, padding, kernel_initializer=initializer, use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:58:42.036018Z","iopub.execute_input":"2025-02-12T12:58:42.036356Z","iopub.status.idle":"2025-02-12T12:58:42.044302Z","shell.execute_reply.started":"2025-02-12T12:58:42.036327Z","shell.execute_reply":"2025-02-12T12:58:42.043329Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_generator(input_shape, conv_num, res_num, upsample_num):\n    filters = 64\n    inputs = layers.Input(shape=input_shape)\n    \n    x = convolutional_block(x=inputs, filters=filters, kernel_size=7, strides=1)\n    for _ in range(conv_num-1):\n        filters *= 2\n        x = convolutional_block(x=x, filters=filters)\n\n    for _ in range(res_num):\n        x = residual_block(x=x, filters=filters, kernel_size=3)\n  \n    for _ in range(upsample_num):\n        filters = max(64, int(filters/2))\n        x = upsample_block(x, filters)\n    initializer = tf.random_normal_initializer(0., 0.02)\n    # Mapping features to RGB\n    outputs = layers.Conv2D(filters=3, kernel_size=7, strides=1, padding='same', kernel_initializer=initializer, activation='tanh')(x)\n    model = models.Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:58:44.873473Z","iopub.execute_input":"2025-02-12T12:58:44.873818Z","iopub.status.idle":"2025-02-12T12:58:44.880332Z","shell.execute_reply.started":"2025-02-12T12:58:44.873779Z","shell.execute_reply":"2025-02-12T12:58:44.879299Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\nconv_num = 3\nres_num = 6 if input_shape[0] == 128 else 9\nup_num = 2","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:58:47.010729Z","iopub.execute_input":"2025-02-12T12:58:47.011107Z","iopub.status.idle":"2025-02-12T12:58:47.015688Z","shell.execute_reply.started":"2025-02-12T12:58:47.011075Z","shell.execute_reply":"2025-02-12T12:58:47.01463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# G will mapping from X to Y\ngenerator_G = build_generator(input_shape, conv_num, res_num, up_num)\n\n# F will mapping from Y to X\ngenerator_F = build_generator(input_shape, conv_num, res_num, up_num)","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:58:49.735529Z","iopub.execute_input":"2025-02-12T12:58:49.736429Z","iopub.status.idle":"2025-02-12T12:58:50.288786Z","shell.execute_reply.started":"2025-02-12T12:58:49.736389Z","shell.execute_reply":"2025-02-12T12:58:50.288087Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Discriminator","metadata":{}},{"cell_type":"code","source":"def discriminator_block(x, filters, kernel_size=4, strides=2, padding='same', norm=True, act=True):\n    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)\n    if norm: x = layers.BatchNormalization()(x)\n    if act: x = layers.LeakyReLU(negative_slope=0.2)(x)\n    return x\n\ndef build_discriminator(input_shape):\n    inp = layers.Input(shape=input_shape, name='input_image')\n    tar = layers.Input(shape=input_shape, name='target_image')\n\n    x = layers.Concatenate()([inp, tar])\n    \n    filters = 64\n    n_down = 3\n    x = discriminator_block(x, filters, norm=False)\n    for i in range(n_down):\n        x = discriminator_block(x, filters*2**(i+1), strides=1 if i == (n_down-1) else 2)\n    out = discriminator_block(x, 1, strides=1, norm=False, act=False)\n    model = models.Model(inputs=[inp, tar], outputs=[out])\n    return model","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:58:51.708877Z","iopub.execute_input":"2025-02-12T12:58:51.709759Z","iopub.status.idle":"2025-02-12T12:58:51.716615Z","shell.execute_reply.started":"2025-02-12T12:58:51.709722Z","shell.execute_reply":"2025-02-12T12:58:51.715804Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"discriminator_Y = build_discriminator(input_shape)\ndiscriminator_X = build_discriminator(input_shape)","metadata":{"execution":{"iopub.status.busy":"2025-02-12T12:58:55.037812Z","iopub.execute_input":"2025-02-12T12:58:55.03843Z","iopub.status.idle":"2025-02-12T12:58:55.176715Z","shell.execute_reply.started":"2025-02-12T12:58:55.038392Z","shell.execute_reply":"2025-02-12T12:58:55.17603Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Losses","metadata":{}},{"cell_type":"code","source":"LAMDA = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:58:57.431959Z","iopub.execute_input":"2025-02-12T12:58:57.432312Z","iopub.status.idle":"2025-02-12T12:58:57.436366Z","shell.execute_reply.started":"2025-02-12T12:58:57.432285Z","shell.execute_reply":"2025-02-12T12:58:57.435438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:01.486274Z","iopub.execute_input":"2025-02-12T12:59:01.486888Z","iopub.status.idle":"2025-02-12T12:59:01.490868Z","shell.execute_reply.started":"2025-02-12T12:59:01.486853Z","shell.execute_reply":"2025-02-12T12:59:01.48999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generator_loss(disc_generated_output, gen_output, target):\n    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n    return gan_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:03.604915Z","iopub.execute_input":"2025-02-12T12:59:03.605866Z","iopub.status.idle":"2025-02-12T12:59:03.610483Z","shell.execute_reply.started":"2025-02-12T12:59:03.605817Z","shell.execute_reply":"2025-02-12T12:59:03.609554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def discriminator_loss(disc_real_output, disc_generated_output):\n    real_loss = tf.reduce_mean(tf.square(tf.ones_like(disc_real_output) - disc_real_output))\n    \n    generated_loss = tf.reduce_mean(tf.square(tf.zeros_like(disc_generated_output) - disc_generated_output))\n    \n    total_disc_loss = real_loss + generated_loss\n    \n    return total_disc_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:05.922638Z","iopub.execute_input":"2025-02-12T12:59:05.922989Z","iopub.status.idle":"2025-02-12T12:59:05.927671Z","shell.execute_reply.started":"2025-02-12T12:59:05.922945Z","shell.execute_reply":"2025-02-12T12:59:05.926789Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimizier","metadata":{}},{"cell_type":"code","source":"class LinearDecaySchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, lr, step_per_epoch):\n        self.lr = lr\n        self.final_lr = 0\n        self.step_per_epoch = step_per_epoch\n\n    def __call__(self, step):\n        epoch = tf.cast(step, tf.float32) // tf.cast(self.step_per_epoch, tf.float32)\n\n        # Use tf.cond() to avoid graph errors\n        return tf.cond(\n            epoch < 100,\n            lambda: self.lr,  # If in warmup, return initial LR\n            lambda: self.lr - ((self.lr - self.final_lr) * (epoch - 100) / epoch)  # Else, decay LR\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:08.262035Z","iopub.execute_input":"2025-02-12T12:59:08.262377Z","iopub.status.idle":"2025-02-12T12:59:08.268Z","shell.execute_reply.started":"2025-02-12T12:59:08.26235Z","shell.execute_reply":"2025-02-12T12:59:08.26703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr = 2e-4\nstep_per_epoch = len(train_dataset)\nlr_scheduler = LinearDecaySchedule(lr, step_per_epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:13.025691Z","iopub.execute_input":"2025-02-12T12:59:13.026448Z","iopub.status.idle":"2025-02-12T12:59:13.031347Z","shell.execute_reply.started":"2025-02-12T12:59:13.02641Z","shell.execute_reply":"2025-02-12T12:59:13.030605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_G = tf.keras.optimizers.Adam(lr_scheduler)\noptimizer_F = tf.keras.optimizers.Adam(lr_scheduler)\noptimizer_X = tf.keras.optimizers.Adam(lr_scheduler)\noptimizer_Y = tf.keras.optimizers.Adam(lr_scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:15.549225Z","iopub.execute_input":"2025-02-12T12:59:15.550055Z","iopub.status.idle":"2025-02-12T12:59:15.560488Z","shell.execute_reply.started":"2025-02-12T12:59:15.550019Z","shell.execute_reply":"2025-02-12T12:59:15.559616Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate images","metadata":{}},{"cell_type":"code","source":"def generate_images(model, test_input, tar):\n    prediction = model(test_input, training=True)\n    plt.figure(figsize=(15, 15))\n\n    display_list = [test_input[0], tar[0], prediction[0]]\n    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n\n    for i in range(3):\n        plt.subplot(1, 3, i+1)\n        plt.title(title[i])\n\n        plt.imshow(display_list[i] * 0.5 + 0.5)\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:27.304087Z","iopub.execute_input":"2025-02-12T12:59:27.304439Z","iopub.status.idle":"2025-02-12T12:59:27.310253Z","shell.execute_reply.started":"2025-02-12T12:59:27.304407Z","shell.execute_reply":"2025-02-12T12:59:27.309305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for example_input, example_target in test_dataset.take(1):\n    generate_images(generator_G, example_input, example_target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:29.871929Z","iopub.execute_input":"2025-02-12T12:59:29.872309Z","iopub.status.idle":"2025-02-12T12:59:31.755798Z","shell.execute_reply.started":"2025-02-12T12:59:29.872276Z","shell.execute_reply":"2025-02-12T12:59:31.755014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/\"\n\nckpt = tf.train.Checkpoint(generator_G=generator_G,\n                           generator_F=generator_F,\n                           discriminator_X=discriminator_X,\n                           discriminator_Y=discriminator_Y,\n                           optimizer_G=optimizer_G,\n                           optimizer_F=optimizer_F,\n                           optimizer_X=optimizer_X,\n                           optimizer_Y=optimizer_Y)\n\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n\nif ckpt_manager.latest_checkpoint:\n  ckpt.restore(ckpt_manager.latest_checkpoint)\n  print ('Latest checkpoint restored!!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T12:59:36.972162Z","iopub.execute_input":"2025-02-12T12:59:36.972736Z","iopub.status.idle":"2025-02-12T12:59:37.323087Z","shell.execute_reply.started":"2025-02-12T12:59:36.972701Z","shell.execute_reply":"2025-02-12T12:59:37.322192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef train_step(input_image, target_image):\n    with tf.GradientTape(persistent=True) as tape:\n        # GAN Loss of Generator G mapping from X -> Y\n        fake_Y = generator_G(input_image, training=True)\n        \n        disc_real_Y = discriminator_Y([input_image, target_image], training=True)\n        disc_fake_Y = discriminator_Y([input_image, fake_Y], training=True)\n        \n        G_gan_loss = tf.reduce_mean(tf.square(tf.ones_like(disc_fake_Y) - disc_fake_Y))\n        Y_disc_loss = discriminator_loss(disc_real_Y, disc_fake_Y)\n\n        # GAN Loss of Generator F mapping from Y -> X\n        fake_X = generator_F(target_image, training=True)\n        \n        disc_real_X = discriminator_X([target_image, input_image], training=True)\n        disc_fake_X = discriminator_X([target_image, fake_X], training=True)\n\n        F_gan_loss = tf.reduce_mean(tf.square(tf.ones_like(disc_fake_X) - disc_fake_X))\n        X_disc_loss = discriminator_loss(disc_real_X, disc_fake_X)\n\n        # Cycle-Consistent Loss\n        cycled_Y = generator_G(fake_X, training=True)\n        cycled_X = generator_F(fake_Y, training=True)\n        G_l1_loss = tf.reduce_mean(tf.abs(target_image - cycled_Y))\n        F_l1_loss = tf.reduce_mean(tf.abs(input_image - cycled_X))\n\n        cycle_loss = G_l1_loss + F_l1_loss\n        total_loss = G_gan_loss + F_gan_loss + cycle_loss * LAMDA\n    \n    # Calculate gradients for generators\n    G_gradients = tape.gradient(total_loss, generator_G.trainable_variables)\n    F_gradients = tape.gradient(total_loss, generator_F.trainable_variables)\n\n    # Calculate gradients for discriminators\n    Y_gradients = tape.gradient(Y_disc_loss, discriminator_Y.trainable_variables)\n    X_gradients = tape.gradient(X_disc_loss, discriminator_X.trainable_variables)\n\n    # Apply gradients to the optimizers\n    optimizer_G.apply_gradients(zip(G_gradients, generator_G.trainable_variables))\n    optimizer_F.apply_gradients(zip(F_gradients, generator_F.trainable_variables))\n\n    optimizer_Y.apply_gradients(zip(Y_gradients, discriminator_Y.trainable_variables))\n    optimizer_X.apply_gradients(zip(X_gradients, discriminator_X.trainable_variables))\n    \n    return G_gan_loss, Y_disc_loss, F_gan_loss, X_disc_loss, total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T09:36:02.911705Z","iopub.execute_input":"2025-02-10T09:36:02.91212Z","iopub.status.idle":"2025-02-10T09:36:02.920985Z","shell.execute_reply.started":"2025-02-10T09:36:02.912093Z","shell.execute_reply":"2025-02-10T09:36:02.920262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_sample = len(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T09:36:02.925202Z","iopub.execute_input":"2025-02-10T09:36:02.925562Z","iopub.status.idle":"2025-02-10T09:36:02.932285Z","shell.execute_reply.started":"2025-02-10T09:36:02.925535Z","shell.execute_reply":"2025-02-10T09:36:02.931536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit(train_ds, test_ds, start_epoch=0, end_epoch=100):\n    example_input, example_target = next(iter(test_ds.take(1)))\n\n    for epoch in range(start_epoch, end_epoch):\n        train_G_loss = 0.0\n        train_Y_loss = 0.0\n        train_F_loss = 0.0\n        train_X_loss = 0.0\n        total_loss = 0.0\n        \n        # Training and display the progress with every 10%\n        print(f\"Epoch {epoch + 1}/{end_epoch}\")\n        start = time.time()\n\n        for step, (input_image, target) in train_ds.enumerate():\n            \n            G_loss, Y_loss, F_loss, X_loss, total = train_step(input_image, target)\n            train_G_loss += G_loss\n            train_Y_loss += Y_loss\n            train_F_loss += F_loss\n            train_X_loss += X_loss\n            total_loss += total\n  \n            if (step+1) % (num_sample // 10) == 0:\n                print('.', end='', flush=True)\n             \n        display.clear_output(wait=True)\n        \n        print(f\"Time: {time.time() - start:.2f} sec\\n\"\n        f\"G Loss: {train_G_loss/num_sample}, Y Loss: {train_Y_loss/num_sample}\\n\"\n        f\"F Loss: {train_F_loss/num_sample}, X Loss: {train_X_loss/num_sample}\\n\"\n        f\"Total Loss: {total_loss/num_sample}\")\n\n        # Display an instance\n        generate_images(generator_G, example_input, example_target)\n        generate_images(generator_F, example_target, example_input)\n        \n        # Save the checkpoint\n        if (epoch + 1) % 5 == 0:\n            ckpt_save_path = ckpt_manager.save()\n            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T09:36:02.933397Z","iopub.execute_input":"2025-02-10T09:36:02.933699Z","iopub.status.idle":"2025-02-10T09:36:02.941628Z","shell.execute_reply.started":"2025-02-10T09:36:02.93367Z","shell.execute_reply":"2025-02-10T09:36:02.940779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fit(train_dataset, test_dataset, 100, 200)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T09:36:02.94256Z","iopub.execute_input":"2025-02-10T09:36:02.942873Z","iopub.status.idle":"2025-02-10T13:05:46.122367Z","shell.execute_reply.started":"2025-02-10T09:36:02.942825Z","shell.execute_reply":"2025-02-10T13:05:46.121463Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"from skimage.metrics import structural_similarity as ssim\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:29:46.494616Z","iopub.execute_input":"2025-02-12T13:29:46.495299Z","iopub.status.idle":"2025-02-12T13:29:46.500827Z","shell.execute_reply.started":"2025-02-12T13:29:46.495263Z","shell.execute_reply":"2025-02-12T13:29:46.499566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_fcn_scores(model_G, model_F, dataset):\n    stoi = []\n    itos = []\n\n    for image, y_true  in dataset:\n        y_pred_a = model_G.predict([image], verbose=0)  # Add batch dimension\n        y_pred_b = model_F.predict([y_true], verbose=0)\n        \n        y_true = y_true[0].numpy().astype(np.float32)\n        stoi.append(ssim(y_true,\n                      y_pred_a[0],\n                      data_range=y_pred_a[0].max() - y_pred_a[0].min(),\n                      channel_axis=-1))\n        \n        image = image[0].numpy().astype(np.float32)\n        itos.append(ssim(image,\n                      y_pred_b[0],\n                      data_range=y_pred_b[0].max() - y_pred_b[0].min(),\n                      channel_axis=-1))\n    return {\n        \"Segmentation -> Image\": np.mean(stoi),\n        \"Image -> Segmentation\": np.mean(itos)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:55:27.555246Z","iopub.execute_input":"2025-02-12T13:55:27.556122Z","iopub.status.idle":"2025-02-12T13:55:27.562541Z","shell.execute_reply.started":"2025-02-12T13:55:27.556084Z","shell.execute_reply":"2025-02-12T13:55:27.561573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"compute_fcn_scores(generator_G, generator_F, train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:55:52.435957Z","iopub.execute_input":"2025-02-12T13:55:52.436845Z","iopub.status.idle":"2025-02-12T13:56:58.081864Z","shell.execute_reply.started":"2025-02-12T13:55:52.436796Z","shell.execute_reply":"2025-02-12T13:56:58.08092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"compute_fcn_scores(generator_G, generator_F, test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T13:55:30.160423Z","iopub.execute_input":"2025-02-12T13:55:30.161025Z","iopub.status.idle":"2025-02-12T13:55:47.510695Z","shell.execute_reply.started":"2025-02-12T13:55:30.160955Z","shell.execute_reply":"2025-02-12T13:55:47.509708Z"}},"outputs":[],"execution_count":null}]}